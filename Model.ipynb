{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Read the data into a pandas data frame \n",
    "df = pd.read_parquet(\"de_train.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalizes data between -1 and 1\n",
    "#returns normalized data and the factors used to normalzie \n",
    "def normalize(df):\n",
    "    min = df.min()\n",
    "    max=df.max()\n",
    "    df_normalized = (df - min) / (max-min)\n",
    "    return df_normalized, min.reset_index(drop=True), max.reset_index(drop=True)\n",
    "\n",
    "\n",
    "#unnormalize\n",
    "def unnormalize(normalized_df, min, max):\n",
    "    return min + normalized_df*(max-min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################DATA PREP###############################\n",
    "\n",
    "\n",
    "\n",
    "####One hot incodes inputs####\n",
    "\n",
    "# Initialize the OneHotEncoder\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "\n",
    "# Fit and transform the data\n",
    "cells = df[\"cell_type\"].values.reshape(-1, 1)\n",
    "hot_cells = encoder.fit_transform(cells)\n",
    "cell_mapping = encoder.categories_[0]\n",
    "\n",
    "compounds = df['sm_name'].values.reshape(-1, 1)\n",
    "hot_compounds = encoder.fit_transform(compounds)\n",
    "compound_mapping = encoder.categories_[0]\n",
    "\n",
    "#Puts together inputs\n",
    "inputs = np.hstack((hot_cells, hot_compounds))\n",
    "inputs_df = pd.DataFrame(data = inputs)\n",
    "\n",
    "\n",
    "####Normalizes Outputs####\n",
    "\n",
    "outputs = df.loc[:, 'A1BG':'ZZEF1']\n",
    "outputs_norm_df, norm_min, norm_max = normalize(outputs)\n",
    "\n",
    "\n",
    "####Puts Inputs and Outputs Together####\n",
    "prepped_df = pd.concat([inputs_df, outputs_norm_df], axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Break into training and validation and split inputs from outputs\n",
    "val, train = train_test_split(prepped_df, train_size=.2, random_state=3)\n",
    "trainIn_df = train.loc[:, 0:151]\n",
    "trainOut_df = train.loc[:, 'A1BG':'ZZEF1']\n",
    "valIn_df = val.loc[:,0:151]\n",
    "valOut_df = val.loc[:, 'A1BG':'ZZEF1']\n",
    "\n",
    "#Transforms data frames into tensors\n",
    "trainIn_t = torch.tensor(trainIn_df.values)\n",
    "trainOut_t = torch.tensor(trainOut_df.values)\n",
    "valIn_t = torch.tensor(valIn_df.values)\n",
    "valOut_t = torch.tensor(valOut_df.values)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Layer1(\n",
       "  (fc1): Linear(in_features=152, out_features=1024, bias=True)\n",
       "  (relu1): ReLU()\n",
       "  (fc2): Linear(in_features=1024, out_features=18211, bias=True)\n",
       "  (act_output): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Build each layer of nueral network\n",
    "#Provide forward method to train network\n",
    "class Layer1(nn.Module):\n",
    "    def __init__(self, input_size, hidden1_size, num_classes):\n",
    "        #Initialzing layers\n",
    "        super(Layer1, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden1_size)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden1_size, num_classes)\n",
    "        self.act_output = nn.Sigmoid()\n",
    "    #training function\n",
    "    def forward(self,x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu1(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.act_output(out)\n",
    "        return out\n",
    "    \n",
    "#Instantiate class with input, hidden layer, and output size \n",
    "model1 = Layer1(152,1024,18211)\n",
    "#Change to double data type\n",
    "model1.double()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Layer2(\n",
       "  (fc1): Linear(in_features=152, out_features=1024, bias=True)\n",
       "  (relu1): ReLU()\n",
       "  (fc2): Linear(in_features=1024, out_features=16384, bias=True)\n",
       "  (relu2): ReLU()\n",
       "  (fc3): Linear(in_features=16384, out_features=18211, bias=True)\n",
       "  (act_output): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Build each layer of nueral network\n",
    "#Provide forward method to train network\n",
    "class Layer2(nn.Module):\n",
    "    def __init__(self, input_size, hidden1_size, hidden2_size, num_classes):\n",
    "        #Initialzing layers\n",
    "        super(Layer2, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden1_size)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden1_size, hidden2_size)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.fc3 = nn.Linear(hidden2_size, num_classes)\n",
    "        self.act_output = nn.Sigmoid()\n",
    "    #training function\n",
    "    def forward(self,x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu1(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.relu2(out)\n",
    "        out = self.fc3(out)\n",
    "        out = self.act_output(out)\n",
    "        return out\n",
    "    \n",
    "#Instantiate class with input, hidden layer, and output size \n",
    "model2 = Layer2(152,1024,16384,18211)\n",
    "#Change to double data type\n",
    "model2.double()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model1.parameters(), lr = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute accuracy (no_grad is optional)\n",
    "def deviation():\n",
    "    with torch.no_grad():\n",
    "        y_pred = model1(valIn_t)\n",
    "\n",
    "    accuracy = (abs((y_pred-valOut_t)).sum()/valOut_t.sum())\n",
    "    RSS = ((y_pred-valOut_t)**2).float().sum()\n",
    "    return (f\"Deviation: {100*accuracy}%    RSS: {RSS}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training loop \n",
    "def train(epoch_number, batch_size):\n",
    "    for epoch in range(epoch_number):\n",
    "        for i in range(0, len(trainIn_t), batch_size):\n",
    "            Xbatch = trainIn_t[i:i+batch_size]\n",
    "            y_pred = model1(Xbatch)\n",
    "            ybatch = trainOut_t[i:i+batch_size]\n",
    "            loss = loss_fn(y_pred, ybatch)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print(f\"Finished epoch {epoch}, {deviation()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished epoch 0, Deviation: 16.987750766192093%    RSS: 14888.9794921875\n",
      "Finished epoch 1, Deviation: 11.502041864867389%    RSS: 10640.060546875\n",
      "Finished epoch 2, Deviation: 10.413547972350983%    RSS: 9816.6962890625\n",
      "Finished epoch 3, Deviation: 10.412823916296894%    RSS: 9592.947265625\n",
      "Finished epoch 4, Deviation: 10.443866959519632%    RSS: 9481.0654296875\n",
      "Finished epoch 5, Deviation: 10.47323764687515%    RSS: 9418.9765625\n",
      "Finished epoch 6, Deviation: 10.49935704980965%    RSS: 9383.62109375\n",
      "Finished epoch 7, Deviation: 10.52190857881625%    RSS: 9359.4052734375\n",
      "Finished epoch 8, Deviation: 10.545011069479763%    RSS: 9336.7021484375\n",
      "Finished epoch 9, Deviation: 10.567792305572265%    RSS: 9306.642578125\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Train model (epochs, mini batch size)\n",
    "train(10,20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Deviation: 8.229646555430483%    RSS: 26338.72265625'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute accuracy on training set \n",
    "def deviationtrain():\n",
    "    with torch.no_grad():\n",
    "        y_pred = model1(trainIn_t)\n",
    "\n",
    "    accuracy = (abs((y_pred-trainOut_t)).sum()/trainOut_t.sum())\n",
    "    RSS = ((y_pred-trainOut_t)**2).float().sum()\n",
    "    return (f\"Deviation: {100*accuracy}%    RSS: {RSS}\")\n",
    "\n",
    "deviationtrain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hot_encode(cell,compound):\n",
    "    cell_vec = np.zeros(cell_mapping.size)\n",
    "    cell_dict = {value: index for index, value in enumerate(cell_mapping)}\n",
    "\n",
    "    compound_vec = np.zeros(compound_mapping.size)\n",
    "    compound_dict = {value: index for index, value in enumerate(compound_mapping)}\n",
    "\n",
    "\n",
    "    cell_vec[cell_dict[cell]]=1\n",
    "    compound_vec[compound_dict[compound]]=1\n",
    "    vector = np.concatenate((cell_vec, compound_vec), axis = 0)\n",
    "    tensor = torch.from_numpy(vector)\n",
    "    return tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1425, 0.2461, 0.4919,  ..., 0.4428, 0.4528, 0.5499],\n",
       "       dtype=torch.float64, grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1(hot_encode(\"NK cells\", \"Clotrimazole\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        0.352196\n",
      "1        0.481949\n",
      "2       -0.950288\n",
      "3       -0.373793\n",
      "4        0.814279\n",
      "           ...   \n",
      "18206    0.312108\n",
      "18207    0.039815\n",
      "18208    0.209169\n",
      "18209   -0.390617\n",
      "18210   -0.224997\n",
      "Length: 18211, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "def get_expression(cell_type, compound_name):\n",
    "    tensor = model1(hot_encode(cell_type,compound_name))\n",
    "    np_array = tensor.detach().numpy()\n",
    "    df = pd.DataFrame(np_array)\n",
    "    return unnormalize(df[0],norm_min,norm_max)\n",
    "\n",
    "\n",
    "df = get_expression(\"NK cells\", \"Clotrimazole\")\n",
    "print(df)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the sample submission and test set ID map\n",
    "sample_submission = pd.read_csv(\"sample_submission.csv\")\n",
    "testDf = pd.read_csv(\"id_map.csv\")\n",
    "\n",
    "# Initialize an empty list to collect the predicted values\n",
    "predicted_values = []\n",
    "\n",
    "# Loop through the test set to get the predicted values\n",
    "for idx, row in testDf.iterrows():\n",
    "    cell_type = row['cell_type']\n",
    "    sm_name = row['sm_name']\n",
    "    \n",
    "    # Call your get_expression method here\n",
    "    expression_values = get_expression(cell_type, sm_name)\n",
    "    \n",
    "    # Append the values to the list\n",
    "    predicted_values.append(expression_values)\n",
    "\n",
    "# Convert the list of predicted values to a numpy array\n",
    "predicted_values_array = np.array(predicted_values)\n",
    "\n",
    "# Replace the values in the sample submission DataFrame\n",
    "sample_submission.iloc[:, 1:] = predicted_values_array\n",
    "\n",
    "# Save the DataFrame to a new CSV file\n",
    "sample_submission.to_csv(\"my_submission.csv\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
